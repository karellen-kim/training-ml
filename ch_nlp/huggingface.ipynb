{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e709ba6c-5ed3-4b61-b3b5-b72331410818",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de5de976-af8c-4325-97b9-1d5a3c3c368d",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation_en_to_fr\") # 기본 모델 T5-base 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'translation_text': \"Le soleil s'élève dans les collines.\"}]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"The sun is rising amid the hills.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "8e8895a5-223f-4a9a-9267-edd65287e855",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1e8ae20-8b07-40ee-b66c-daace786717a",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "textClassifier = pipeline(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'NEGATIVE', 'score': 0.9846920371055603}]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textClassifier(\"Call me Ishmael. \\\n",
    "Some years ago—never mind how long precisely—having little \\\n",
    "or no money in my purse, and nothing particular to interest me on shore, \\\n",
    "I thought I would sail about a little and see the watery part of the world. \\\n",
    "It is a way I have of driving off the spleen, and regulating the circulation.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'NEGATIVE', 'score': 0.810395359992981},\n {'label': 'POSITIVE', 'score': 0.9776005148887634}]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textClassifier([\"To be, or not to be\",\"With mirth and laughter let old wrinkles come\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 텍스트 추론 (Natural Language Inference : NLI)\n",
    "* 문장이 참(entailment), 거짓(contradiction), 중립(neutral)인지 가려낸다"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "nliClassifier = pipeline(\"text-classification\", model = \"roberta-large-mnli\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'ENTAILMENT', 'score': 0.7261566519737244}]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nliClassifier(\"Staying clean is a good thing. Hygiene is a lovely thing.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'CONTRADICTION', 'score': 0.9656215906143188}]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nliClassifier(\"Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world. I have a waterphobia.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'NEUTRAL', 'score': 0.5616686940193176}]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nliClassifier(\"Cats were represented in social and religious practices of ancient Egypt for more than 3,000 years. Power systems is a major subfield of Electrical Engineering.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## QNLI\n",
    "* 문장이 가설과 관련된 정보를 포함하고 있는지 알 수 있다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "qnliClassifier = pipeline(\"text-classification\", model = \"cross-encoder/qnli-electra-base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_0', 'score': 0.0025376155972480774}]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnliClassifier(\"What's the major subfield of Electrical Engineering?, Staying clean is a good thing.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_0', 'score': 0.7401779294013977}]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnliClassifier(\"What's the major subfield of Electrical Engineering?, Power and Electronics engineerings are usually preferred by new undergrad students.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question Answering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "qaModel = pipeline(\"question-answering\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 0.9327439069747925, 'start': 111, 'end': 115, 'answer': 'grey'}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage = \"THE TIME TRAVELLER (for so it will be convenient to speak of him) \\\n",
    "was expounding a recondite matter to us. \\\n",
    "His grey eyes shone and twinkled, and his usually pale face was flushed \\\n",
    "and animated. The fire burned brightly, and the soft radiance of the \\\n",
    "incandescent lights in the lilies of silver caught the bubbles \\\n",
    "that flashed and passed in our glasses. \\\n",
    "Our chairs, being his patents, embraced and caressed us rather than submitted \\\n",
    "to be sat upon, and there was that luxurious after-dinner atmosphere \\\n",
    "when thought runs gracefully free of the trammels of precision. \\\n",
    "And he put it to us in this way—marking the points with a lean forefinger—as \\\n",
    "we sat and lazily admired his earnestness over this new paradox \\\n",
    "(as we thought it) and his fecundity.\"\n",
    "\n",
    "qaModel(\"What was colour of time traveller eyes?\", passage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 0.06857698410749435,\n 'start': 351,\n 'end': 361,\n 'answer': 'Our chairs'}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qaModel(\"Where were we sitting?\", passage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 0.0344405323266983,\n 'start': 107,\n 'end': 139,\n 'answer': 'His grey eyes shone and twinkled'}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qaModel(\"What was our reaction to time traveller?\", passage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 문법 수정하기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "grammarClassifier = pipeline(\"text-classification\", model = \"textattack/distilbert-base-uncased-CoLA\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_0', 'score': 0.6497087478637695}]"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammarClassifier(\"he go to school everyday out missing the bus\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_1', 'score': 0.9765014052391052}]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammarClassifier(\"This chapter will provide an overview of performing common NLP tasks.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 토큰 분류\n",
    "* 2가지 step이 있다\n",
    "  * Named Entity Recognition (NER)\n",
    "  * Part-of-Speech (PoS) tagging"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5e1067d-69bf-4d6a-91c3-d78f47156d8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "tokenClassifier = pipeline(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'entity': 'I-PER',\n  'score': 0.9345262,\n  'index': 1,\n  'word': 'Ptolemy',\n  'start': 0,\n  'end': 7},\n {'entity': 'I-MISC',\n  'score': 0.9682059,\n  'index': 5,\n  'word': 'G',\n  'start': 24,\n  'end': 25},\n {'entity': 'I-MISC',\n  'score': 0.8515827,\n  'index': 6,\n  'word': '##eo',\n  'start': 25,\n  'end': 27},\n {'entity': 'I-MISC',\n  'score': 0.86348933,\n  'index': 7,\n  'word': '##graph',\n  'start': 27,\n  'end': 32},\n {'entity': 'I-MISC',\n  'score': 0.92860067,\n  'index': 8,\n  'word': '##ia',\n  'start': 32,\n  'end': 34},\n {'entity': 'I-LOC',\n  'score': 0.991808,\n  'index': 12,\n  'word': 'Lab',\n  'start': 49,\n  'end': 52},\n {'entity': 'I-LOC',\n  'score': 0.9888537,\n  'index': 13,\n  'word': '##ok',\n  'start': 52,\n  'end': 54},\n {'entity': 'I-LOC',\n  'score': 0.9976913,\n  'index': 14,\n  'word': '##la',\n  'start': 54,\n  'end': 56},\n {'entity': 'I-LOC',\n  'score': 0.99820256,\n  'index': 23,\n  'word': 'Lahore',\n  'start': 101,\n  'end': 107}]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenClassifier(\"Ptolemy mentions in his Geographia a city called Labokla which may have been in reference to ancient Lahore.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "posTagger = pipeline(\"token-classification\", model = \"vblagoje/bert-english-uncased-finetuned-pos\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'entity': 'PROPN',\n  'score': 0.9985763,\n  'index': 1,\n  'word': 'ptolemy',\n  'start': 0,\n  'end': 7},\n {'entity': 'VERB',\n  'score': 0.99952936,\n  'index': 2,\n  'word': 'mentions',\n  'start': 8,\n  'end': 16},\n {'entity': 'ADP',\n  'score': 0.9994611,\n  'index': 3,\n  'word': 'in',\n  'start': 17,\n  'end': 19},\n {'entity': 'PRON',\n  'score': 0.998919,\n  'index': 4,\n  'word': 'his',\n  'start': 20,\n  'end': 23},\n {'entity': 'PROPN',\n  'score': 0.5962589,\n  'index': 5,\n  'word': 'geo',\n  'start': 24,\n  'end': 27},\n {'entity': 'PROPN',\n  'score': 0.77628046,\n  'index': 6,\n  'word': '##graph',\n  'start': 27,\n  'end': 32},\n {'entity': 'NOUN',\n  'score': 0.6260992,\n  'index': 7,\n  'word': '##ia',\n  'start': 32,\n  'end': 34},\n {'entity': 'DET',\n  'score': 0.9993963,\n  'index': 8,\n  'word': 'a',\n  'start': 35,\n  'end': 36},\n {'entity': 'NOUN',\n  'score': 0.9986626,\n  'index': 9,\n  'word': 'city',\n  'start': 37,\n  'end': 41},\n {'entity': 'VERB',\n  'score': 0.9963213,\n  'index': 10,\n  'word': 'called',\n  'start': 42,\n  'end': 48},\n {'entity': 'PROPN',\n  'score': 0.997322,\n  'index': 11,\n  'word': 'lab',\n  'start': 49,\n  'end': 52},\n {'entity': 'PROPN',\n  'score': 0.9933227,\n  'index': 12,\n  'word': '##ok',\n  'start': 52,\n  'end': 54},\n {'entity': 'PROPN',\n  'score': 0.9967691,\n  'index': 13,\n  'word': '##la',\n  'start': 54,\n  'end': 56},\n {'entity': 'PRON',\n  'score': 0.9993855,\n  'index': 14,\n  'word': 'which',\n  'start': 57,\n  'end': 62},\n {'entity': 'AUX',\n  'score': 0.9985049,\n  'index': 15,\n  'word': 'may',\n  'start': 63,\n  'end': 66},\n {'entity': 'AUX',\n  'score': 0.9961761,\n  'index': 16,\n  'word': 'have',\n  'start': 67,\n  'end': 71},\n {'entity': 'AUX',\n  'score': 0.99127114,\n  'index': 17,\n  'word': 'been',\n  'start': 72,\n  'end': 76},\n {'entity': 'ADP',\n  'score': 0.99933344,\n  'index': 18,\n  'word': 'in',\n  'start': 77,\n  'end': 79},\n {'entity': 'NOUN',\n  'score': 0.9973694,\n  'index': 19,\n  'word': 'reference',\n  'start': 80,\n  'end': 89},\n {'entity': 'ADP',\n  'score': 0.9994091,\n  'index': 20,\n  'word': 'to',\n  'start': 90,\n  'end': 92},\n {'entity': 'ADJ',\n  'score': 0.99520975,\n  'index': 21,\n  'word': 'ancient',\n  'start': 93,\n  'end': 100},\n {'entity': 'PROPN',\n  'score': 0.9989177,\n  'index': 22,\n  'word': 'lahore',\n  'start': 101,\n  'end': 107},\n {'entity': 'PUNCT',\n  'score': 0.9996501,\n  'index': 23,\n  'word': '.',\n  'start': 107,\n  'end': 108}]"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posTagger(\"Ptolemy mentions in his Geographia a city called Labokla which may have been in reference to ancient Lahore.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 텍스트 요약"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\") # default로 distilbart-cnn-12-6 모델 사용"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'summary_text': ' There are really four dimensions, three which we call the three planes of Space, and a fourth, Time . There is a tendency to'}]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\"“Filby became pensive. “Clearly,” the Time Traveller proceeded, “any real body must have extension in four directions: it must have Length, Breadth, Thickness, and—Duration. But through a natural infirmity of the flesh, which I will explain to you in a moment, we incline to overlook this fact. There are really four dimensions, three which we call the three planes of Space, and a fourth, Time. There is, however, a tendency to draw an unreal distinction between the former three dimensions and the latter, because it happens that our consciousness moves intermittently in one direction along the latter from the beginning to the end of our lives.”\", min_length=10, max_length=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 다른 모델로 요약하기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'summary_text': '\"There are really four dimensions, three which we call the three planes of Space, and a fourth, Time\" \"Our consciousness moves'}]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bartLargeSummarizer = pipeline(\"summarization\", \"facebook/bart-large-cnn\")\n",
    "bartLargeSummarizer(\"“Filby became pensive. “Clearly,” the Time Traveller proceeded, “any real body must have extension in four directions: it must have Length, Breadth, Thickness, and—Duration. But through a natural infirmity of the flesh, which I will explain to you in a moment, we incline to overlook this fact. There are really four dimensions, three which we call the three planes of Space, and a fourth, Time. There is, however, a tendency to draw an unreal distinction between the former three dimensions and the latter, because it happens that our consciousness moves intermittently in one direction along the latter from the beginning to the end of our lives.”\", min_length=10, max_length=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text Generation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<00:00, 153kB/s]\n",
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 548M/548M [01:23<00:00, 6.59MB/s] \n",
      "Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<00:00, 17.1kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:02<00:00, 503kB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:01<00:00, 271kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:02<00:00, 577kB/s]\n"
     ]
    }
   ],
   "source": [
    "gpt2Generator = pipeline(\"text-generation\", model=\"gpt2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': 'Generative Pre-trained Transformer 3 (GPT-3) is an autoregressive language model that uses deep learning to produce human-like text. \\xa0A recurrent neural network (NFC) of a machine learns to create an artificial language with low complexity. \\xa0 This novel model uses neural network architectures where there are high-dimensional information for each of the three inputs with a high probability of finding information of the highest order. \\xa0The NFC is then trained to recognize sentences that are of high probability and those that cannot. \\xa0For instance, a speaker from a group of non-verbal groups may see several words that do the same thing, and may recognize the same sentence. \\xa0If one fails to recognize sentences in a corpus, the system will learn over time over and over more complex representations, each of which will learn something different. \\xa0 The goal for this model is to create a language that allows one to create a different kind of world, from a single speaker'},\n {'generated_text': 'Generative Pre-trained Transformer 3 (GPT-3) is an autoregressive language model that uses deep learning to produce human-like text. \\xa0The GPT-3\\'s ability to capture natural phrasing allows it to produce an intuitively human-like representation of English, a language that has been dubbed the \"native English.\" (The term \"English\" is also a contraction of British word meaning \"from something.\") The text is read by researchers in different way and with varying levels of understanding of the grammatical concepts and vocabulary. \\xa0With a GPT-3, each piece would appear to possess the right vocabulary but also the right sentence structure. \\xa0This helps produce a novel narrative of a language that has been lost during the development stages. \\xa0That understanding is then conveyed to researchers in laboratories.\\nIn a few months, GPT-3 participants will get to test the theory with experimentally-prepared grammatically correct prose paper.\\n'},\n {'generated_text': 'Generative Pre-trained Transformer 3 (GPT-3) is an autoregressive language model that uses deep learning to produce human-like text. \\xa0The model is based on the GPT-3 model that is a combination of real life-based and machine learning tasks. \\xa0Asynchronous processing (APR) is accomplished with various neural networks and other neural systems, but GPT-3 relies on the GPT network.\\nThe GPT network was implemented in both JavaScript and Python to produce text on the gpt-web, where we defined the syntax:\\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\\nGPT-5: \\xa0The \\xa0type of data received by the model is the corpus of text on the GPT-web. \\xa0The data is used for processing, where it is applied to learn how the text is translated into the text being'}]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2Generator(\"Generative Pre-trained Transformer 3 (GPT-3) is an autoregressive language model that uses deep learning to produce human-like text. \", max_length = 200, num_return_sequences=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/eunmi.kim/Library/Caches/pypoetry/virtualenvs/pythonproject-lXhPpjWq-py3.8/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text2textGenerator = pipeline(\"text2text-generation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'generated_text': 'Physicist'}]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2textGenerator(\"question: Who was Feynman ? context: Richard Feynman was a Physicist. Being one of the most famous scientist ever, he is still remembered in the scientific society.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fill Mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'score': 0.26325371861457825,\n  'token': 4811,\n  'token_str': ' foundation',\n  'sequence': 'DNA is the foundation of life.'},\n {'score': 0.11198776215314865,\n  'token': 1453,\n  'token_str': ' basis',\n  'sequence': 'DNA is the basis of life.'},\n {'score': 0.06848201155662537,\n  'token': 22157,\n  'token_str': ' spice',\n  'sequence': 'DNA is the spice of life.'},\n {'score': 0.03729137405753136,\n  'token': 14981,\n  'token_str': ' essence',\n  'sequence': 'DNA is the essence of life.'},\n {'score': 0.034392744302749634,\n  'token': 9813,\n  'token_str': ' origin',\n  'sequence': 'DNA is the origin of life.'}]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskFiller = pipeline(\"fill-mask\")\n",
    "maskFiller(\"DNA is the <mask> of life.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}